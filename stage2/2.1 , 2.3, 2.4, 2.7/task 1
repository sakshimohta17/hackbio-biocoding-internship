#www.linkedin.com/in/sakshimohta1705


import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np
from scipy.stats import ttest_ind
import urllib.request
import io

# Load dataset
url = "https://raw.githubusercontent.com/HackBio-Internship/2025_project_collection/refs/heads/main/Python/Dataset/mcgc.tsv"
response = urllib.request.urlopen(url)
df = pd.read_csv(io.StringIO(response.read().decode('utf-8')), sep='\t')

# Function to determine time to reach carrying capacity
def carrying_capacity_time(df, strain, strain_type):
    strain_data = df[(df['Strain'] == strain) & (df['Type'] == strain_type)]
    carrying_capacity = strain_data['OD600'].max()
    time_to_capacity = strain_data[strain_data['OD600'] >= 0.95 * carrying_capacity]['Time'].min()
    return time_to_capacity

# Get unique strains
time_to_capacity = []
strains = df['Strain'].unique()

# Plot growth curves
for strain in strains:
    plt.figure(figsize=(8, 5))
    for strain_type in ['-', '+']:
        subset = df[(df['Strain'] == strain) & (df['Type'] == strain_type)]
        if not subset.empty:
            plt.plot(subset['Time'], subset['OD600'], label=f"{strain_type} strain")
    plt.xlabel('Time (hours)')
    plt.ylabel('OD600')
    plt.title(f'Growth Curve for {strain}')
    plt.legend()
    plt.show()
    
    # Store time to carrying capacity
    for strain_type in ['-', '+']:
        if not df[(df['Strain'] == strain) & (df['Type'] == strain_type)].empty:
            time_to_capacity.append([strain, carrying_capacity_time(df, strain, strain_type), strain_type])

# Convert time-to-capacity data into a DataFrame
time_df = pd.DataFrame(time_to_capacity, columns=['Strain', 'Time_to_Capacity', 'Type'])

# Scatter plot of carrying capacity times
plt.figure(figsize=(8, 5))
sns.scatterplot(data=time_df, x='Type', y='Time_to_Capacity', hue='Strain')
plt.xlabel("Strain Type")
plt.ylabel("Time to Carrying Capacity (hours)")
plt.title("Scatter Plot of Carrying Capacity Time")
plt.legend()
plt.show()

# Box plot of carrying capacity times
plt.figure(figsize=(8, 5))
sns.boxplot(data=time_df, x='Type', y='Time_to_Capacity')
plt.xlabel("Strain Type")
plt.ylabel("Time to Carrying Capacity (hours)")
plt.title("Box Plot of Carrying Capacity Time")
plt.show()

# Statistical analysis
knockout_times = time_df[time_df['Type'] == '-']['Time_to_Capacity']
knockin_times = time_df[time_df['Type'] == '+']['Time_to_Capacity']

stat, p_value = ttest_ind(knockout_times, knockin_times, equal_var=False, nan_policy='omit')
print(f"T-test p-value: {p_value}")

# Interpretation of statistical results
if p_value < 0.05:
    print("There is a significant difference in the time to carrying capacity between knock-out and knock-in strains.")
else:
    print("No significant difference found between knock-out and knock-in strains.")

# Observations:
# - If knock-out strains take significantly longer to reach carrying capacity, it may suggest impaired growth.
# - If knock-in strains reach carrying capacity faster, it may indicate a growth advantage.
# - The boxplot and scatter plot provide a visual representation of these differences.

# Step 1: Load the datasets
sift_df = pd.read_csv("external_data/sift.csv")
foldx_df = pd.read_csv("external_data/foldx.csv")

# Create specific_Protein_aa column
sift_df["specific_Protein_aa"] = sift_df["Protein"] + "_" + sift_df["Amino_Acid"]
foldx_df["specific_Protein_aa"] = foldx_df["Protein"] + "_" + foldx_df["Amino_Acid"]

# Merge datasets on specific_Protein_aa
merged_df = pd.merge(sift_df, foldx_df, on="specific_Protein_aa", suffixes=("_sift", "_foldx"))

# Find mutations affecting both structure and function
deleterious_mutations = merged_df[(merged_df["sift_Score"] < 0.05) & (merged_df["foldX_Score"] > 2)]

# Extract the first amino acid from Amino_Acid column
deleterious_mutations["Initial_AA"] = deleterious_mutations["Amino_Acid_sift"].str[0]

# Generate a frequency table
aa_frequency = deleterious_mutations["Initial_AA"].value_counts()

# Plot bar chart
plt.figure(figsize=(10,5))
sns.barplot(x=aa_frequency.index, y=aa_frequency.values, palette="viridis")
plt.xlabel("Amino Acid")
plt.ylabel("Frequency")
plt.title("Frequency of Amino Acids with High Impact Mutations")
plt.show()

# Plot pie chart
plt.figure(figsize=(8,8))
plt.pie(aa_frequency, labels=aa_frequency.index, autopct='%1.1f%%', colors=sns.color_palette("viridis", len(aa_frequency)))
plt.title("Distribution of High Impact Amino Acids")
plt.show()

# Analyze the most frequent high-impact amino acid
most_impactful_aa = aa_frequency.idxmax()
impactful_count = aa_frequency.max()
print(f"The amino acid with the highest impact on protein structure and function is {most_impactful_aa} with {impactful_count} occurrences.")

# Analyze structural and functional properties of amino acids occurring more than 100 times
high_occurrence_aa = aa_frequency[aa_frequency > 100]
print("Amino acids with more than 100 occurrences:")
print(high_occurrence_aa)

# Task code 2.7:

# Public Health
# NHANES is a program run by the CDC to assess the health and nutritional status of adults and children in the US.
# It combines survey questions and physical examinations, including medical and physiological measurements and laboratory tests, and examines a representative sample of about 5,000 people each year.
# The data is used to determine the prevalence of diseases and risk factors, establish national standards, and support epidemiology studies and health sciences research.
# This information helps to develop public health policy, design health programs and services, and expand the nation's health knowledge.

# 1. Import datasets

# URLs for dataset and data dictionary
dataset_url = "https://raw.githubusercontent.com/HackBio-Internship/public_datasets/main/R/nhanes.csv"
data_dict_url = "https://raw.githubusercontent.com/HackBio-Internship/public_datasets/main/R/nhanes_dd.csv"

# Load dataset and data dictionary
df = pd.read_csv(dataset_url)  # load Url1
data_dict = pd.read_csv(data_dict_url)  # Load Url2

# Display first few rows
print("Dataset Sample:")
print(df.head())

print("\nData Dictionary Sample:")
print(data_dict.head())

# Check column names in both files
print("\nDataset Columns:", df.columns.tolist())
print("\nData Dictionary Columns:", data_dict.columns.tolist())

# Assuming the data dictionary contains variable names and descriptions
# We will merge them based on the column name
if "Variable Name" in data_dict.columns and "Description" in data_dict.columns:
    variable_info = data_dict[["Variable Name", "Description"]]

    # Display a preview of variable information
    print("\nVariable Information Sample:")
    print(variable_info.head())
else:
    print("Check the column names in the data dictionary!")

# Save locally if needed
df.to_csv("nhanes_data.csv", index=False)
data_dict.to_csv("nhanes_data_dict.csv", index=False)


